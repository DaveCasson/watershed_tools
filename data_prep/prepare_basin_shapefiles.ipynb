{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare basin GRU (hydrologic unit or HUC) and flowline shapefiles ###\n",
    "\n",
    "#### If these don't both pre-exist, run this script before all other scripts ####\n",
    "\n",
    "This script includes:<br>\n",
    "1a. if needed, extract basin GRU shapefile from a large-domain GRU shapefile.<br> \n",
    "1b. write basin hucId.txt list\n",
    "2. extract basin flowlines shapefile from a large-domain flowlines shapefile.<br>\n",
    "3. reproject basin GRU and flowlines shapefiles to a common equal coordinate system. <br>\n",
    "The script also makes some directories used in the discretization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os, sys\n",
    "sys.path.append('../')\n",
    "import functions.geospatial_analysis as ga\n",
    "import functions.utils as ut\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from rasterio.warp import Resampling\n",
    "import functions.ogr2ogr as ogr2ogr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up paths, filenames, directories ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common paths\n",
    "control_file    = '../control.tpl.txt'\n",
    "source_path     = ut.read_from_control(control_file, 'source_path')           # must exist with input full-domain data\n",
    "basin_data_path = ut.read_from_control(control_file, 'basin_data_path')\n",
    "basin_name      = ut.read_from_control(control_file, 'basin_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make standard directories\n",
    "if not os.path.exists(basin_data_path):\n",
    "    os.makedirs(basin_data_path)\n",
    "plot_path  = os.path.join(basin_data_path, 'plots/')\n",
    "if not os.path.exists(plot_path):\n",
    "    os.makedirs(plot_path)\n",
    "gis_path  = os.path.join(basin_data_path, 'gis/')\n",
    "if not os.path.exists(gis_path):\n",
    "    os.makedirs(gis_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projection system\n",
    "new_epsg = ut.read_from_control(control_file, 'epsg') \n",
    "dest_crs = rio.crs.CRS.from_epsg(new_epsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set basin shapefiles\n",
    "basin_gru_shp       = ut.read_from_control(control_file, 'basin_gru_shp')  # may exist\n",
    "basin_flowlines_shp = ut.set_filename(control_file, 'basin_flowlines_shp') # may exist; is always _prj\n",
    "\n",
    "# derived filenames\n",
    "basin_gru_prj_shp   = basin_gru_shp.split('.shp')[0]+'_prj.shp'\n",
    "\n",
    "# huc fieldname and text file\n",
    "huc_fieldname       = ut.read_from_control(control_file, 'huc_fieldname')      \n",
    "basin_hucId_txt     = ut.set_filename(control_file, 'basin_hucId_txt')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU field definitions      # used?\n",
    "gruNo_fieldname   = ut.read_from_control(control_file, 'gruNo_fieldname')    \n",
    "gruNo_field_dtype = ut.read_from_control(control_file, 'gruNo_field_dtype')\n",
    "gruId_fieldname   = ut.read_from_control(control_file, 'gruId_fieldname')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set basin GRU shapefile (extract from larger full-domain if needed) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the basin shapefile doesn't exist, it needs to be extracted from another larger HUC/GRU shapefile\n",
    "if not os.path.exists(basin_gru_shp):\n",
    "\n",
    "    # ---- extract basin GRU shapefile and ID list from a larger full-domain GRU / HUC shapefile ---- \n",
    "\n",
    "    # read filename and other necessary info\n",
    "    fulldom_huc_shp   = ut.read_from_control(control_file, 'fulldom_huc_shpfile')\n",
    "    outlet_hucId      = ut.read_from_control(control_file, 'outlet_hucId')\n",
    "    toHuc_fieldname   = ut.read_from_control(control_file, 'toHuc_fieldname')\n",
    "    data = gpd.read_file(fulldom_huc_shp)\n",
    "    \n",
    "    # check whether two useful columns (huc_field, toHuc_field) are in huc_shp.\n",
    "    if not huc_fieldname in data.columns.values:\n",
    "        exit(huc_fieldname + ' column does not exist in shapefile.')\n",
    "    else:\n",
    "        hucs = data[huc_fieldname].values\n",
    "    if not toHuc_fieldname in data.columns.values:\n",
    "        exit(toHuc_fieldname + ' column does not exist in shapefile.')\n",
    "    else:\n",
    "        tohucs = data[toHuc_fieldname].values\n",
    "    # extract only the useful columns to save data memory.\n",
    "    data = data[[huc_fieldname, toHuc_fieldname, 'geometry']] \n",
    "\n",
    "    # ---- search upstream HUCs ---- \n",
    "    # method 1: search upstream hucs base on the most downstream hucId\n",
    "    upstream_hucs = [outlet_hucid]                              # list of upstream hucs. initiate with outlet_hucid\n",
    "    huc_found     = np.unique(hucs[np.where(tohucs==outlet_hucId)]) # find all the upstream hucs that drain to outlet_hucid.\n",
    "    upstream_hucs.extend(list(huc_found))                       # add the found upstream hucs of outlet_hucid to upstream_hucs list\n",
    "    round_num     = 0                                               # record the round number of searching.\n",
    "\n",
    "    while len(huc_found) != 0: # terminate searching upstream hucs until no one can be found any more.\n",
    "        round_num = round_num+1\n",
    "        print(\"Round %d: %d HUCs found.\" % (round_num, len(upstream_hucs)))\n",
    "\n",
    "        # search upstream hucs\n",
    "        huc_found_next = []\n",
    "        for huc_i in huc_found:\n",
    "            huc_found_next.extend(list(hucs[np.where(tohucs==huc_i)]))\n",
    "        huc_found_next = unique(huc_found_next)\n",
    "\n",
    "        # identify if the found HUCs exist in upstrm_hucs\n",
    "        huc_found = [huc for huc in huc_found_next if not huc in upstream_hucs]\n",
    "        upstream_hucs.extend(huc_found)\n",
    "\n",
    "        # alternate method: manually add upstream_hucs when the list of upstream hucs is known. \n",
    "        #upstream_hucs= np.loadtxt('/glade/u/home/andywood/proj/SHARP/wreg/bighorn/prep/lists/hucIds.06279940.txt',dtype=int)\n",
    "\n",
    "    # ---- save upstream GRU shapefile ---- \n",
    "    data[data[huc_fieldname].isin(upstream_hucs)].to_file(basin_gru_shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the basin shapefile and write hucId list\n",
    "data = gpd.read_file(basin_gru_shp)\n",
    "if not huc_fieldname in data.columns.values:\n",
    "    exit(huc_fieldname + ' column does not exist in shapefile ', basin_gru_shp)\n",
    "else:\n",
    "    hucs = data[huc_fieldname].values\n",
    "    \n",
    "if 'int' in str(hucs.dtype):\n",
    "    np.savetxt(basin_hucId_txt, hucs, fmt='%d')\n",
    "else:\n",
    "    np.savetxt(basin_hucId_txt, hucs, fmt='%s')\n",
    "print('wrote hucId file for the target basin %s: %s' % (basin_name, basin_hucId_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if needed, reproject basin GRU shapefile\n",
    "if not os.path.exists(basin_gru_prj_shp):\n",
    "    ga.reproject_vector(basin_gru_shp, basin_gru_prj_shp, new_epsg)\n",
    "print('reprojected basin GRUs:', basin_gru_prj_shp)\n",
    "\n",
    "# Alternative method: use ogr2ogr\n",
    "#if not os.path.exists(basin_gru_prj_shp):\n",
    "#    ga.reproject_basin_shapefile(basin_gru_shp, basin_gru_prj_shp, dst_crs)\n",
    "#in_gdf_prj = gpd.read_file(basin_gru_prj_shp)    # read projected file in using geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract basin flowline shapefile ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- extract basin flowlines from full-dom flowlines file if needed\n",
    "if not os.path.exists(basin_flowlines_shp):\n",
    "    \n",
    "    # may need to reproject full-domain flowlines shapefile first\n",
    "    flowlines_shp     = ut.read_from_control(control_file, 'fulldom_flowlines_shp')\n",
    "    flowlines_prj_shp = flowlines_shp.split('.shp')[0]+'_prj.shp' \n",
    "    if not os.path.exists(flowlines_prj_shp):\n",
    "        ga.reproject_vector(flowlines_shp, flowlines_prj_shp, new_epsg)\n",
    "        print('reprojected full domain streams:', flowlines_prj_shp)\n",
    "        \n",
    "    # read stream and boundary files (projected)\n",
    "    flowlines_gpd = gpd.read_file(flowlines_prj_shp)\n",
    "    basin_gru_gpd = gpd.read_file(basin_gru_prj_shp)\n",
    "    print('read reprojected shapefiles for clipping flowlines')    \n",
    "\n",
    "    # create basin outer boundary shapefile \n",
    "    tmp_gpd                = basin_gru_gpd[['geometry']]\n",
    "    basin_gru_gpd['null_column'] = 0\n",
    "    basin_boundary_gpd     = basin_gru_gpd.dissolve(by='null_column')\n",
    "    basin_boundary_prj_shp = basin_gru_prj_shp.split('.shp')[0]+'_boundary.shp'\n",
    "    basin_boundary_gpd.to_file(basin_boundary_prj_shp)\n",
    "    print('wrote basin boundary shapefile to use in stream clipping:', basin_boundary_prj_shp) \n",
    "    \n",
    "    # clip full-dom reprojected flowlines with basin boundary     \n",
    "    #   note: if geopandas version < 0.7, cannot use clip(), so instead use ogr2ogr\n",
    "    if float(gpd.__version__.split(\".\")[0]+\".\"+gpd.__version__.split(\".\")[1]) >= 0.7:\n",
    "        in_gpd_clip = gpd.clip(flowlines_gpd, basin_boundary_gpd)\n",
    "        in_gpd_clip.to_file(basin_flowlines_prj_shp)\n",
    "    else:\n",
    "        print('Note: using ogr2ogr to clip streams to basin')\n",
    "        driverName = 'ESRI Shapefile'    # can later be upgraded to work with geopackages (eg 'GPKG')\n",
    "        ogr2ogr.main([\"\", \"-f\", driverName, \"-clipsrc\", basin_boundary_prj_shp, basin_flowlines_prj_shp, flowlines_prj_shp]) \n",
    "    print('wrote basin-clipped stream shapefile:', basin_flowlines_prj_shp)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pangeo (2019.09.12 - py3.7)",
   "language": "python",
   "name": "pangeo-2019.09.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
