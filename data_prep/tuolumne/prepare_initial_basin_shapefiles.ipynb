{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare basin GRU (hydrologic unit or GRU) and flowline shapefiles ###\n",
    "\n",
    "#### If these don't both pre-exist, run this script before all other scripts ####\n",
    "\n",
    "This script includes:<br>\n",
    "1a. if needed, extract basin GRU shapefile from a large-domain GRU shapefile.<br> \n",
    "1b. write basin gruId.txt list\n",
    "2. extract basin flowlines shapefile from a large-domain flowlines shapefile.<br>\n",
    "3. reproject basin GRU and flowlines shapefiles to a common equal coordinate system. <br>\n",
    "The script also makes some directories used in the discretization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os, sys\n",
    "sys.path.append('../')\n",
    "import functions.geospatial_analysis as ga\n",
    "import functions.utils as ut\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from rasterio.warp import Resampling\n",
    "import functions.ogr2ogr as ogr2ogr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up paths, filenames, directories ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common paths\n",
    "control_file    = '../../control/control.txt.tuolumne'\n",
    "basin_data_path = ut.read_from_control(control_file, 'basin_data_path')\n",
    "basin_name      = ut.read_from_control(control_file, 'basin_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make standard directories\n",
    "if not os.path.exists(basin_data_path):\n",
    "    os.makedirs(basin_data_path)\n",
    "plot_path  = os.path.join(basin_data_path, 'plots/')\n",
    "if not os.path.exists(plot_path):\n",
    "    os.makedirs(plot_path)\n",
    "gis_path  = os.path.join(basin_data_path, 'gis/')\n",
    "if not os.path.exists(gis_path):\n",
    "    os.makedirs(gis_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projection system\n",
    "new_epsg = ut.read_from_control(control_file, 'epsg') \n",
    "dest_crs = rio.crs.CRS.from_epsg(new_epsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set basin shapefiles\n",
    "basin_gru_shp           = ut.set_filename(control_file, 'basin_gru_shp')  # may exist\n",
    "basin_flowlines_shp     = ut.set_filename(control_file, 'basin_flowlines_shp') # may exist; is always _prj\n",
    "\n",
    "# gru fieldname and text file\n",
    "gru_fieldname           = ut.read_from_control(control_file, 'gru_fieldname')      \n",
    "basin_gruId_txt         = ut.set_filename(control_file, 'basin_gruId_txt')\n",
    "\n",
    "# derived filenames\n",
    "basin_gru_prj_shp       = basin_gru_shp.split('.shp')[0]+'_prj.shp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set basin GRU shapefile (extract from larger full-domain if needed) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the basin shapefile doesn't exist, it needs to be extracted from another larger GRU shapefile\n",
    "if not os.path.exists(basin_gru_shp):\n",
    "\n",
    "    # ---- extract basin GRU shapefile and ID list from a larger full-domain GRU shapefile ---- \n",
    "\n",
    "    # read filename and other necessary info\n",
    "    fulldom_gru_shp   = ut.read_from_control(control_file, 'fulldom_gru_shpfile')\n",
    "    outlet_gruId      = ut.read_from_control(control_file, 'basin_outlet_gruId')\n",
    "    toGRU_fieldname   = ut.read_from_control(control_file, 'toGRU_fieldname')\n",
    "    data              = gpd.read_file(fulldom_gru_shpfile)\n",
    "    \n",
    "    # check whether two useful columns (gru_field, toGRU_field) are in gru_shp.\n",
    "    if not gru_fieldname in data.columns.values:\n",
    "        exit(gru_fieldname + ' column does not exist in shapefile.')\n",
    "    else:\n",
    "        grus = data[gru_fieldname].values\n",
    "    if not toGRU_fieldname in data.columns.values:\n",
    "        exit(toGRU_fieldname + ' column does not exist in shapefile.')\n",
    "    else:\n",
    "        togrus = data[toGRU_fieldname].values\n",
    "    # extract only the useful columns to save data memory.\n",
    "    data = data[[gru_fieldname, toGRU_fieldname, 'geometry']] \n",
    "\n",
    "    # ---- search upstream GRUs ---- \n",
    "    # method 1: search upstream grus base on the most downstream gruId\n",
    "    upstream_grus = [outlet_gruid]           # list of upstream grus. initiate with outlet_gruid\n",
    "    gru_found     = np.unique(grus[np.where(togrus==outlet_gruId)]) # find all the upstream grus that drain to outlet_gruid.\n",
    "    upstream_grus.extend(list(gru_found))    # add the found upstream grus of outlet_gruid to upstream_grus list\n",
    "    round_num     = 0                        # record the round number of searching.\n",
    "\n",
    "    while len(gru_found) != 0: # terminate searching upstream grus until no one can be found any more.\n",
    "        round_num = round_num+1\n",
    "        print(\"Round %d: %d GRUs found.\" % (round_num, len(upstream_grus)))\n",
    "\n",
    "        # search upstream grus\n",
    "        gru_found_next = []\n",
    "        for gru_i in gru_found:\n",
    "            gru_found_next.extend(list(grus[np.where(togrus==gru_i)]))\n",
    "        gru_found_next = unique(gru_found_next)\n",
    "\n",
    "        # identify if the found GRUs exist in upstrm_grus\n",
    "        gru_found = [gru for gru in gru_found_next if not gru in upstream_grus]\n",
    "        upstream_grus.extend(gru_found)\n",
    "\n",
    "        # alternate method: manually add upstream_grus when the list of upstream grus is known. \n",
    "        #upstream_grus= np.loadtxt('/glade/u/home/andywood/proj/SHARP/wreg/bighorn/prep/lists/gruIds.06279940.txt',dtype=int)\n",
    "\n",
    "    # ---- save upstream GRU shapefile ---- \n",
    "    data[data[gru_fieldname].isin(upstream_grus)].to_file(basin_gru_shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote gruId file for the target basin tuolumne: /glade/work/andywood/complexity/basins/smada/tuolumne/gruIds.txt\n"
     ]
    }
   ],
   "source": [
    "# read the basin shapefile and write gruId list\n",
    "data = gpd.read_file(basin_gru_shp)\n",
    "if not gru_fieldname in data.columns.values:\n",
    "    exit(gru_fieldname + ' column does not exist in shapefile ', basin_gru_shp)\n",
    "else:\n",
    "    grus = data[gru_fieldname].values\n",
    "    \n",
    "if 'int' in str(grus.dtype):\n",
    "    np.savetxt(basin_gruId_txt, grus, fmt='%d')\n",
    "else:\n",
    "    np.savetxt(basin_gruId_txt, grus, fmt='%s')\n",
    "print('wrote gruId file for the target basin %s: %s' % (basin_name, basin_gruId_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reprojected basin GRUs: /glade/work/andywood/complexity/basins/smada/tuolumne/gis/huc12x.tuolumne_prj.shp\n"
     ]
    }
   ],
   "source": [
    "# reproject basin GRU shapefile if it doesn't exist\n",
    "if not os.path.exists(basin_gru_prj_shp):\n",
    "    ga.reproject_vector(basin_gru_shp, basin_gru_prj_shp, new_epsg)\n",
    "print('reprojected basin GRUs:', basin_gru_prj_shp)\n",
    "\n",
    "# Alternative method: use ogr2ogr\n",
    "#if not os.path.exists(basin_gru_prj_shp):\n",
    "#    ga.reproject_basin_shapefile(basin_gru_shp, basin_gru_prj_shp, dst_crs)\n",
    "#in_gdf_prj = gpd.read_file(basin_gru_prj_shp)    # read projected file in using geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract basin flowline shapefile ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read reprojected shapefiles for clipping flowlines\n",
      "wrote basin boundary shapefile to use in stream clipping: /glade/work/andywood/complexity/basins/smada/tuolumne/gis/huc12x.tuolumne_prj_boundary.shp\n",
      "Note: using ogr2ogr to clip streams to basin, writing /glade/work/andywood/complexity/basins/smada/tuolumne/gis/flowlines_prj.shp\n",
      "wrote basin-clipped stream shapefile: /glade/work/andywood/complexity/basins/smada/tuolumne/gis/flowlines_prj.shp\n"
     ]
    }
   ],
   "source": [
    "# -- extract basin flowlines from full-dom flowlines file if it doesn't exist\n",
    "#    note that the basin flowlines shapefile will be in the common projected coordinates (new_epsg)\n",
    "#    this step can take a few minutes (wait for 'done')\n",
    "if not os.path.exists(basin_flowlines_shp):\n",
    "    \n",
    "    # may need to reproject full-domain flowlines shapefile first\n",
    "    flowlines_shp     = ut.read_from_control(control_file, 'fulldom_flowlines_shp')\n",
    "    flowlines_prj_shp = flowlines_shp.split('.shp')[0]+'_prj.shp' \n",
    "    if not os.path.exists(flowlines_prj_shp):\n",
    "        ga.reproject_vector(flowlines_shp, flowlines_prj_shp, new_epsg)\n",
    "        print('reprojected full domain streams:', flowlines_prj_shp)\n",
    "        \n",
    "    # read stream and boundary files (projected)\n",
    "    flowlines_gpd = gpd.read_file(flowlines_prj_shp)\n",
    "    basin_gru_gpd = gpd.read_file(basin_gru_prj_shp)\n",
    "    print('read reprojected shapefiles for clipping flowlines')    \n",
    "\n",
    "    # create basin outer boundary shapefile \n",
    "    tmp_gpd                  = basin_gru_gpd[['geometry']]\n",
    "    basin_gru_gpd['tmp_col'] = 0         # create null column for dissolve\n",
    "    basin_boundary_gpd       = basin_gru_gpd.dissolve(by='tmp_col')\n",
    "    basin_boundary_prj_shp   = basin_gru_prj_shp.split('.shp')[0]+'_boundary.shp'\n",
    "    basin_boundary_gpd.to_file(basin_boundary_prj_shp)\n",
    "    print('wrote basin boundary shapefile to use in stream clipping:', basin_boundary_prj_shp) \n",
    "    \n",
    "    # clip full-dom reprojected flowlines with basin boundary     \n",
    "    #   note: if geopandas version < 0.7, cannot use clip(), so instead use ogr2ogr\n",
    "    if float(gpd.__version__.split(\".\")[0]+\".\"+gpd.__version__.split(\".\")[1]) >= 0.7:\n",
    "        in_gpd_clip = gpd.clip(flowlines_gpd, basin_boundary_gpd)\n",
    "        in_gpd_clip.to_file(basin_flowlines_shp)\n",
    "    else:\n",
    "        print('Note: using ogr2ogr to clip streams to basin')\n",
    "        driverName = 'ESRI Shapefile'    # can later be upgraded to work with geopackages (eg 'GPKG')\n",
    "        ogr2ogr.main([\"\", \"-f\", driverName, \"-clipsrc\", basin_boundary_prj_shp, basin_flowlines_shp, flowlines_prj_shp]) \n",
    "        \n",
    "    print('wrote basin-clipped stream shapefile:', basin_flowlines_shp)\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pangeo (2019.09.12 - py3.7)",
   "language": "python",
   "name": "pangeo-2019.09.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
